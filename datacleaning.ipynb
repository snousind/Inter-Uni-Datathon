{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-Uni Datathon: Fraudulent Transaction Detection\n",
    "\n",
    "#### Team Habaybi\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Import Train and Test Datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionNumber</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Age</th>\n",
       "      <th>NumDependents</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>UserTenure</th>\n",
       "      <th>IsFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10966.000000</td>\n",
       "      <td>10966.000000</td>\n",
       "      <td>10966.000000</td>\n",
       "      <td>10966.000000</td>\n",
       "      <td>10923.000000</td>\n",
       "      <td>10923.000000</td>\n",
       "      <td>10966.000000</td>\n",
       "      <td>10966.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9117.500091</td>\n",
       "      <td>2483.885282</td>\n",
       "      <td>2751.845887</td>\n",
       "      <td>1.995714</td>\n",
       "      <td>-30.363255</td>\n",
       "      <td>141.254786</td>\n",
       "      <td>60.786157</td>\n",
       "      <td>0.364308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5293.669640</td>\n",
       "      <td>1429.402615</td>\n",
       "      <td>9730.988917</td>\n",
       "      <td>1.408035</td>\n",
       "      <td>6.962819</td>\n",
       "      <td>11.268395</td>\n",
       "      <td>34.254477</td>\n",
       "      <td>0.481257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.640079</td>\n",
       "      <td>-112.026050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4516.250000</td>\n",
       "      <td>1253.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-37.020100</td>\n",
       "      <td>142.702789</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9120.500000</td>\n",
       "      <td>2471.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-31.840233</td>\n",
       "      <td>144.964600</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13710.750000</td>\n",
       "      <td>3727.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-25.042261</td>\n",
       "      <td>145.612793</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18277.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>67000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.851580</td>\n",
       "      <td>149.012375</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TransactionNumber        UserID           Age  NumDependents  \\\n",
       "count       10966.000000  10966.000000  10966.000000   10966.000000   \n",
       "mean         9117.500091   2483.885282   2751.845887       1.995714   \n",
       "std          5293.669640   1429.402615   9730.988917       1.408035   \n",
       "min             1.000000      1.000000    -68.000000       0.000000   \n",
       "25%          4516.250000   1253.000000     26.000000       1.000000   \n",
       "50%          9120.500000   2471.000000     34.000000       2.000000   \n",
       "75%         13710.750000   3727.000000     43.000000       3.000000   \n",
       "max         18277.000000   5000.000000  67000.000000       4.000000   \n",
       "\n",
       "           Latitude     Longitude    UserTenure       IsFraud  \n",
       "count  10923.000000  10923.000000  10966.000000  10966.000000  \n",
       "mean     -30.363255    141.254786     60.786157      0.364308  \n",
       "std        6.962819     11.268395     34.254477      0.481257  \n",
       "min      -41.640079   -112.026050      1.000000      0.000000  \n",
       "25%      -37.020100    142.702789     31.000000      0.000000  \n",
       "50%      -31.840233    144.964600     61.000000      0.000000  \n",
       "75%      -25.042261    145.612793     90.000000      1.000000  \n",
       "max       57.851580    149.012375    119.000000      1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionNumber', 'UserID', 'Age', 'Gender', 'Occupation',\n",
       "       'EducationLevel', 'MaritalStatus', 'NumDependents', 'Income',\n",
       "       'Expenditure', 'GiftsTransaction', 'TransactionDate', 'TransactionTime',\n",
       "       'TransactionAmount', 'MerchantID', 'TransactionType',\n",
       "       'TransactionLocation', 'DeviceType', 'Latitude', 'Longitude',\n",
       "       'EmailDomain', 'Terrorism', 'UserTenure', 'IsFraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show columns in dataset\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean columns with Financial Data: Complete Currency Conversion to ensure data consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finance_cols = ['Income', 'Expenditure', 'GiftsTransaction', 'TransactionAmount']\n",
    "finance_train = train[['Income', 'Expenditure', 'GiftsTransaction', 'TransactionAmount']]\n",
    "finance_test = test[['Income', 'Expenditure', 'GiftsTransaction', 'TransactionAmount']]\n",
    "\n",
    "def clean_cash(data):\n",
    "    \"\"\" \n",
    "    cleans all columns which contain financial data. Including conversion to AUD, then conversion to float datatype.\n",
    "    \"\"\"\n",
    "    finance_cols = ['Income', 'Expenditure', 'GiftsTransaction', 'TransactionAmount']\n",
    "    \n",
    "    for col in finance_cols:\n",
    "        \n",
    "        data.columns = data.columns.str.replace(' ', '')\n",
    "        data[col] = data[col].str.replace(\"AU$\", \"AUD\", regex=False)\n",
    "        data[col] = data[col].str.replace(\" \", \"\", regex=False)\n",
    "        data[f'{col}2'] = data[col]\n",
    "        data[f'{col}Currency'] = data[col].apply(lambda x: 'AUD' if 'AUD' in str(x) else ('AED' if 'AED' in str(x) else ('GBP' if '£' in str(x) else ('GBP' if 'GBP' in str(x) else ''))))\n",
    "        data[f'{col}2'] = data[f'{col}2'].str.replace(\"AUD\", \"\", regex=False).str.strip()\n",
    "        data[f'{col}2'] = data[f'{col}2'].str.replace(\"AED\", \"\", regex=False).str.strip()\n",
    "        data[f'{col}2'] = data[f'{col}2'].str.replace(\"£\", \"\", regex=False).str.strip()\n",
    "        data[f'{col}2'] = data[f'{col}2'].str.replace(\"GBP\", \"\", regex=False).str.strip()\n",
    "        data[f'{col}2'] = data[f'{col}2'].astype(float)\n",
    "    \n",
    "    data = data.drop(data.columns[:4], axis=1)\n",
    "    data.columns = data.columns.str.replace('2', '')\n",
    "    \n",
    "    \n",
    "    for col in finance_cols:\n",
    "        data.loc[data[f'{col}Currency'] == 'AED', col] = data[col] * 0.41\n",
    "        data.loc[data[f'{col}Currency'] == 'GBP', col] = data[col] * 1.96\n",
    "    \n",
    "    data = data[finance_cols]\n",
    "  \n",
    "    return data\n",
    "\n",
    "cash_train_cleaned = clean_cash(finance_train)\n",
    "cash_test_cleaned = clean_cash(finance_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=finance_cols)\n",
    "train = pd.concat([train, cash_train_cleaned], axis=1)\n",
    "\n",
    "test = test.drop(columns=finance_cols)\n",
    "test = pd.concat([test, cash_test_cleaned], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean DeviceType Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    " # cleaning device column\n",
    "items_to_be_grouped = [\"mob\", \"galaxys7\", \"iphone 15\", \"android\", \"smartphone\"]\n",
    "\n",
    "for device in items_to_be_grouped:\n",
    "    train['DeviceType'] = np.where(train['DeviceType'] == device, \"Mobile\", train[\"DeviceType\"])\n",
    "    test['DeviceType'] = np.where(test['DeviceType'] == device, \"Mobile\", test[\"DeviceType\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean Age Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning Age column\n",
    "train['Age'] = train['Age'].apply(lambda x: abs(x) if x < 0 else x / 1000 if x > 100 else x)\n",
    "test['Age'] = test['Age'].apply(lambda x: abs(x) if x < 0 else x / 1000 if x > 100 else x)\n",
    "\n",
    "train['Age'] = train['Age'].astype(int)\n",
    "test['Age'] = test['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replace_female = [\"Female\", \"fem\", \"she\", \"woman\", \"isnotmale\"]\n",
    "replace_male = [\"Male\", \"he\", \"man\", \"isnotfemale\"]\n",
    "\n",
    "def fix_gender(data):\n",
    "    for index, value in data[\"Gender\"].items():\n",
    "        if value in replace_female:\n",
    "            data.at[index, \"Gender\"] = \"Female\"\n",
    "        elif value in replace_male:\n",
    "            data.at[index, \"Gender\"] = \"Male\"\n",
    "        \n",
    "train['Gender'] = fix_gender(train)\n",
    "test['Gender'] = fix_gender(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-Hot Encode Terrorism Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting terrorism column from bool to int\n",
    "train[\"Terrorism\"] = train[\"Terrorism\"].astype(int)\n",
    "test[\"Terrorism\"] = test[\"Terrorism\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replace_canberra = [\"Canberra\", \"canberra\", \"CBR\", \"Cbr\"]\n",
    "replace_darwin = [\"Darwin\", \"Drw\", \"DRW\", \"darwin\"]\n",
    "replace_adelaide = [\"Adelaide\", \"Adl\", \"Adelaide City\", \"adl\"]\n",
    "replace_sydney = [\"Sydney\", \"SYD\", \"Syd\", \"sydney\"]\n",
    "replace_hobart = [\"Hobart\", \"hobart\", \"HBT\", \"Hbt\"]\n",
    "replace_brisbane = [\"Brisbane\", \"BNE\", \"brisbane\", \"bne\", \"Bne\"]\n",
    "replace_perth = [\"Perth\", \"perth\", \"PTH\", \"pth\", \"Pth\"]\n",
    "replace_melbourne = [\"Melbourne\", \"Melb\", \"melbourne\", \"Mel\", \"MLB\", \"Melburn\"]\n",
    "\n",
    "def replace_location(column, replace_canberra, replace_darwin, replace_adelaide, replace_sydney, replace_hobart, replace_brisbane, replace_perth, replace_melbourne):\n",
    "\t\treplace_dict = {}\n",
    "\t\treplace_dict.update({value: \"Canberra\" for value in replace_canberra})\n",
    "\t\treplace_dict.update({value: \"Darwin\" for value in replace_darwin})\n",
    "\t\treplace_dict.update({value: \"Adelaide\" for value in replace_adelaide})\n",
    "\t\treplace_dict.update({value: \"Sydney\" for value in replace_sydney})\n",
    "\t\treplace_dict.update({value: \"Hobart\" for value in replace_hobart})\n",
    "\t\treplace_dict.update({value: \"Brisbane\" for value in replace_brisbane})\n",
    "\t\treplace_dict.update({value: \"Perth\" for value in replace_perth})\n",
    "\t\treplace_dict.update({value: \"Melbourne\" for value in replace_melbourne})\n",
    "\t\treturn column.replace(replace_dict)\n",
    "\n",
    "train['TransactionLocation'] = replace_location(train['TransactionLocation'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_canberra, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_darwin, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_adelaide, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_sydney, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_hobart, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_brisbane, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_perth, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_melbourne)\n",
    "\n",
    "test['TransactionLocation'] = replace_location(test['TransactionLocation'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_canberra, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_darwin, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_adelaide, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_sydney, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_hobart, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_brisbane, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_perth, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\treplace_melbourne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean Transaction Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean time data\n",
    "def clean_time_column(column):\n",
    "    # First, replace any invalid separators like '/' with ':' \n",
    "    column = column.str.replace('/', ':', regex=False)\n",
    "\n",
    "    # Try converting to datetime in 12-hour format first\n",
    "    dt = pd.to_datetime(column, format='%I:%M:%S %p', errors='coerce')\n",
    "\n",
    "    # If there are any NaT values, try converting to datetime in 24-hour format\n",
    "    dt = dt.fillna(pd.to_datetime(column, format='%H:%M:%S', errors='coerce'))\n",
    "\n",
    "    # Return as strings in 24-hour format\n",
    "    return dt.dt.strftime('%H:%M:%S')\n",
    "\n",
    "# Clean the 'Time' column\n",
    "train['Cleaned_TransactionTime'] = clean_time_column(train['TransactionTime'])\n",
    "test['Cleaned_TransactionTime'] = clean_time_column(test['TransactionTime'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divide Transaction Time into 4 different groups: Night, Morning, Afternoon and Night\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end times for different parts of the day\n",
    "night_start_time = pd.to_datetime('00:00:00').time()\n",
    "night_end_time = pd.to_datetime('05:59:59').time()\n",
    "\n",
    "morning_start_time = pd.to_datetime('06:00:00').time()\n",
    "morning_end_time = pd.to_datetime('11:59:59').time()\n",
    "\n",
    "afternoon_start_time = pd.to_datetime('12:00:00').time()\n",
    "afternoon_end_time = pd.to_datetime('17:59:59').time()\n",
    "\n",
    "evening_start_time = pd.to_datetime('18:00:00').time()\n",
    "evening_end_time = pd.to_datetime('23:59:59').time()\n",
    "\n",
    "# Convert the 'Cleaned_TransactionTime' column to datetime\n",
    "train['Cleaned_TransactionTime'] = pd.to_datetime(train['Cleaned_TransactionTime'])\n",
    "test['Cleaned_TransactionTime'] = pd.to_datetime(test['Cleaned_TransactionTime'])\n",
    "\n",
    "# Function to categorize times of the day\n",
    "def categorize_time_of_day(transaction_time):\n",
    "    time_of_day = transaction_time.time()  # Extract time from datetime\n",
    "    if morning_start_time <= time_of_day < morning_end_time:\n",
    "        return 'Morning'\n",
    "    elif afternoon_start_time <= time_of_day < afternoon_end_time:\n",
    "        return 'Afternoon'\n",
    "    elif evening_start_time <= time_of_day < evening_end_time:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "# Apply the categorization function to the 'Cleaned_TransactionTime' column\n",
    "train['Transaction_Time_of_Day'] = train['Cleaned_TransactionTime'].apply(categorize_time_of_day)\n",
    "train = train.drop(columns='Cleaned_TransactionTime')\n",
    "test['Transaction_Time_of_Day'] = test['Cleaned_TransactionTime'].apply(categorize_time_of_day)\n",
    "test = test.drop(columns='Cleaned_TransactionTime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns={'EmailDomain', 'TransactionTime'})\n",
    "test = test.drop(columns={'EmailDomain', 'TransactionTime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exported cleaned data to csv\n",
    "train.to_csv('train_cleaned.csv')\n",
    "test.to_csv('test_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
